{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2SeqV2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPr6jPpbo/CincKpzcrkX1y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arsuh/Seq2Seq-Chatbot/blob/master/Seq2SeqV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr-v_XT5rDmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb1a9f95-f6b6-47d8-c0bb-ceaa1764bf74"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8d3u8JprJCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b54ea521-2fe4-46dc-8d58-a96ff32678e2"
      },
      "source": [
        "!git clone https://github.com/Arsuh/Seq2Seq-Chatbot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Seq2Seq-Chatbot' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC0ecGJgrdE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "from google.cloud import bigquery\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from shutil import copyfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hFdbi55rUvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd Seq2Seq-Chatbot/\n",
        "from Vocabulary import Vocabulary\n",
        "from MainModel import Encoder, Decoder, loss_fnc\n",
        "\n",
        "drive_main_path = '/content/drive/My Drive/Colab Files/Chatbot/'\n",
        "main_path = '/content/Seq2Seq-Chatbot/'\n",
        "hparams_path = main_path + 'hyper_parameters_std.json'\n",
        "#hparams_path = main_path + 'hyper_parameters_test.json'\n",
        "ckpt_path = drive_main_path + 'ckeckpoints/'\n",
        "ckpt_prefix = os.path.join(ckpt_path, 'ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znI7p--tszr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model(hparams, from_indexed=True, create_ds=True, de_tokenize=False, verbose=False):\n",
        "    start = time.time()\n",
        "    if from_indexed:\n",
        "        v = Vocabulary.create_inputs_from_indexed(service_account.Credentials.from_service_account_file(hparams['CREDENTIALS_PATH']),\n",
        "                                                  max_len=hparams['MAX_LEN'],\n",
        "                                                  vocab=hparams['VOCAB_DB'],\n",
        "                                                  limit_main=hparams['NUM_EXAMPLES'],\n",
        "                                                  limit_vocab=hparams['VOCAB'],\n",
        "                                                  verbose=True)  # <--- False\n",
        "    else:\n",
        "        v = Vocabulary.create_inputs(service_account.Credentials.from_service_account_file(hparams['CREDENTIALS_PATH']),\n",
        "                                     max_len=hparams['MAX_LEN'],\n",
        "                                     vocab=hparams['VOCAB_DB'],\n",
        "                                     limit_main=hparams['NUM_EXAMPLES'],\n",
        "                                     limit_vocab=hparams['VOCAB'],\n",
        "                                     verbose=True)  # <--- False\n",
        "\n",
        "    if de_tokenize:\n",
        "        v.de_tokenize_data()\n",
        "    if verbose:\n",
        "        print('Vocabulary created!')\n",
        "\n",
        "    if create_ds:\n",
        "        dataset = create_dataset(v, hparams['BATCH_SIZE'], hparams['NUM_EXAMPLES'])\n",
        "\n",
        "    enc = Encoder(hparams['VOCAB'], hparams['BATCH_SIZE'], hparams['EMBEDDING'],\n",
        "                  hparams['RNN1'], hparams['RNN2'], hparams['RNN_TYPE'], hparams['BIDIRECTIONAL'], hparams['MERGE_MODE'], hparams['DROPOUT_ENC'])\n",
        "    dec = Decoder(hparams['VOCAB'], hparams['BATCH_SIZE'], hparams['EMBEDDING'],\n",
        "                  hparams['RNN1'], hparams['RNN2'], hparams['RNN_TYPE'], hparams['DROPOUT_DEC'])\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=hparams['LR'])\n",
        "    #opt = tf.keras.optimizers.SGD(learning_rate=hparams['LR'], momentum=0.5)\n",
        "\n",
        "    print('Time to initialize model {:.2f} min | {:.2f} hrs\\n'.format(\n",
        "        (time.time()-start)/60, (time.time()-start)/3600))\n",
        "\n",
        "    if create_ds:\n",
        "        return v, dataset, enc, dec, opt\n",
        "    return v, enc, dec, opt\n",
        "\n",
        "def load_hyper_params(path):\n",
        "    with open(path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for k in data:\n",
        "        if data[k] == 'None':\n",
        "            data[k] = None\n",
        "    return data\n",
        "\n",
        "def create_dataset(v, batch_size, buffer_size):\n",
        "    v.tokenize_data()\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((np.array(v.inp, dtype=np.int32), np.array(v.tar, dtype=np.int32)))\n",
        "    dataset = dataset.shuffle(buffer_size)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def save_plot(path, plt_loss):\n",
        "    if not os.path.isdir(path):\n",
        "        os.mkdir(path)\n",
        "    with open(path + 'plot.txt', 'a', encoding='utf-8') as f:\n",
        "        f.write(str(plt_loss[-1].numpy()) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47Jtsokmx2ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(text, v, enc, dec, max_len):\n",
        "    inp = np.array(v.preproc(text), dtype=np.float32)\n",
        "    inp = tf.convert_to_tensor(inp)\n",
        "    inp = tf.expand_dims(inp, axis=0)\n",
        "\n",
        "    attention_plot = np.zeros((max_len, max_len))\n",
        "\n",
        "    result = ''\n",
        "    h1, h2 = enc.initialize_hidden(batch=1)\n",
        "\n",
        "    enc_out, h1, h2 = enc.call(inp, h1, h2, training=False)\n",
        "    dec_inp = tf.expand_dims([1], axis=0)  # SOS\n",
        "    result += '<SOS> '\n",
        "    for i in range(v.max_len):\n",
        "        pred, h1, h2, attention_weights = dec.call(dec_inp, enc_out, h1, h2, training=False)\n",
        "\n",
        "        pred = tf.nn.softmax(pred, axis=1)\n",
        "        pred_id = tf.argmax(pred[0]).numpy()\n",
        "        #pred_id = tf.random.categorical(pred, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[i] = attention_weights.numpy()\n",
        "\n",
        "        result += v.idx2word[pred_id] + ' '\n",
        "        if pred_id == 2:  # EOS\n",
        "            return result, text, attention_plot\n",
        "\n",
        "        dec_inp = tf.expand_dims([pred_id], axis=0)\n",
        "\n",
        "    return result[:-1], text, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJTJj9Gxxxj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(hparams, inp, tar, enc_h1, enc_h2):\n",
        "    global enc, dec, opt\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_out, enc_h1, enc_h2 = enc(inp, enc_h1, enc_h2)\n",
        "        dec_h1, dec_h2 = enc_h1, enc_h2\n",
        "        dec_inp = tf.expand_dims([1]*hparams['BATCH_SIZE'], 1)\n",
        "\n",
        "        for t in range(1, tar.shape[1]):\n",
        "            pred, dec_h1, dec_h2, _ = dec(dec_inp, enc_out, dec_h1, dec_h2)\n",
        "\n",
        "            loss += loss_fnc(tar[:, t], pred)\n",
        "            dec_inp = tf.expand_dims(tar[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss/int(tar.shape[1]))\n",
        "    variables = enc.trainable_variables + dec.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    opt.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "\n",
        "\n",
        "test_sentences = ['Hello!',\n",
        "                  'How are you?',\n",
        "                  'Tomorow is my birthday, but I keep feeling sad...',\n",
        "                  'What is your name sir?',\n",
        "                  'Artificial intelligence will take over the world some day!',\n",
        "                  'Can you please bring me some water?',\n",
        "                  'Come on! This is the easiest thing you are supposed to do!',\n",
        "                  'My name is Thomas!']\n",
        "\n",
        "\n",
        "def train(hparams, saving=True, saving_step=1, plot_saving=True, verbose=True):\n",
        "    global v, dataset, enc, dec, opt\n",
        "    if hparams['NUM_EXAMPLES'] == None:\n",
        "        N_BATCH = hparams['MAX_EXAMPLES'] // hparams['BATCH_SIZE']\n",
        "    else:\n",
        "        N_BATCH = hparams['NUM_EXAMPLES'] // hparams['BATCH_SIZE']\n",
        "\n",
        "    if saving:\n",
        "        checkpoint = tf.train.Checkpoint(optimizer=opt, encoder=enc, decoder=dec)\n",
        "        if not os.path.isdir(ckpt_path): os.mkdir(ckpt_path)\n",
        "        copyfile(hparams_path, ckpt_path + 'hparams.json')\n",
        "\n",
        "    plt_loss = []\n",
        "    for epoch in range(1, hparams['EPOCHS']+1):\n",
        "        h1, h2 = enc.initialize_hidden()\n",
        "\n",
        "        total_loss = 0\n",
        "        for (batch, (inp, tar)) in enumerate(dataset.take(N_BATCH)):\n",
        "            batch_time = time.time()\n",
        "            batch_loss = train_step(hparams, inp, tar, h1, h2)\n",
        "            total_loss += batch_loss\n",
        "\n",
        "            if batch % 300 == 0:\n",
        "              print('  >>> Epoch: {} | Batch: {}\\\\{} | Loss: {:.4f} | Time: {:.2f} sec'\n",
        "                    .format(epoch, batch+1, N_BATCH, batch_loss, time.time() - batch_time))\n",
        "\n",
        "        print('Epoch: {} | Loss: {:.4f}'.format(epoch+1, total_loss/N_BATCH))\n",
        "        plt_loss.append(total_loss/N_BATCH)\n",
        "\n",
        "        sentences = random.choices(test_sentences, k=2)\n",
        "        result1, text1, _ = evaluate(sentences[0], v, enc, dec, hparams['MAX_LEN'])\n",
        "        result2, text2, _ = evaluate(sentences[1], v, enc, dec, hparams['MAX_LEN'])\n",
        "        print(50*'+')\n",
        "        print(text1)\n",
        "        print(result1)\n",
        "        print(text2)\n",
        "        print(result2)\n",
        "        print(50*'+')\n",
        "\n",
        "        if saving and epoch%saving_step == 0:\n",
        "            print('Saving model...')\n",
        "            checkpoint.save(file_prefix=ckpt_prefix)\n",
        "        if plot_saving:\n",
        "            save_plot(ckpt_path, plt_loss)\n",
        "    return plt_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc7KxiahyPAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = load_hyper_params(hparams_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzLRqQZQyTSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v, dataset, enc, dec, opt = initialize_model(hparams, from_indexed=True, create_ds=True, de_tokenize=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9TUpY3gyHuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#'''\n",
        "checkpoint = tf.train.Checkpoint(optimizer=opt, encoder=enc, decoder=dec)\n",
        "#checkpoint.restore(tf.train.latest_checkpoint(ckpt_path))\n",
        "checkpoint.restore(drive_main_path + 'checkpoints-final-1/' + 'ckpt-2')\n",
        "\n",
        "\n",
        "result, _, _ = evaluate(u'The world is changing once again!', v, enc, dec, hparams['MAX_LEN'])\n",
        "print(result)\n",
        "#'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HwdMrryyJkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt_loss = train(hparams, saving=True, saving_step=5, plot_saving=True)\n",
        "del dataset\n",
        "\n",
        "plt.plot(plt_loss)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}